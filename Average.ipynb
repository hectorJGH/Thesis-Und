{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JJclkivwW5UB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_circles, make_moons, make_swiss_roll\n",
        "from sklearn import preprocessing\n",
        "from functools import reduce #To use multiple np.kron\n",
        "\n",
        "import math\n",
        "\n",
        "import time\n",
        "\n",
        "#from qiskit.quantum_info import state_fidelity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZmYn0loPT6I"
      },
      "source": [
        "# File Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-TNeUziQ_PC",
        "outputId": "d30eab32-2bff-42ea-8a48-1df5b135a0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/julian/Documents/11vo semestre/Tesis/Thesis-Und\n",
            "['Saved_arrays', 'local_library.ipynb', 'local_library.py', 'Average copy.ipynb', '__pycache__', '.git', 'Average.ipynb', '.venv']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "print(os.getcwd())  # Confirm the current working directory\n",
        "print(os.listdir())  # Check for the notebook file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iRPbSz3OB_k",
        "outputId": "100a2f6d-c74e-4966-a3f4-a555392003c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Average copy.ipynb'   local_library.ipynb   \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            " Average.ipynb         local_library.py      \u001b[01;34mSaved_arrays\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "### Asuming we are already in the right directory\n",
        "\n",
        "%ls\n",
        "directory_arrays = './Saved_arrays/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EtJ1tjHfKnsM"
      },
      "outputs": [],
      "source": [
        "#import import_ipynb\n",
        "from local_library import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RylOHvjPXS7K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9caRuYeP2Vy"
      },
      "source": [
        "# Some functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zdbx6C1baEdr"
      },
      "outputs": [],
      "source": [
        "def clasification_and_accuracies(quantum_feature_map, num_points, N_qfm, param_qfm, N_grid, random_seed, dataset_generator, plot = False):\n",
        "\n",
        "    accuracy = np.zeros(3) #pure and mixed and diagonal\n",
        "    dataset = (dataset_generator.__name__)[9:]\n",
        "\n",
        "    train_arr, train_lb, test_arr, test_lb = dataset_generator(num_points, random_seed)\n",
        "\n",
        "    if not plot: N_grid = 1 # It takes small time in the grid\n",
        "\n",
        "    grid_QFM, grid_xy = make_grid(quantum_feature_map, N_qfm, param_qfm, N_grid)\n",
        "\n",
        "    train_QFM_x0, train_QFM_x1, test_QFM_x = make_QFM(quantum_feature_map, N_qfm, param_qfm, train_arr, train_lb, test_arr)\n",
        "\n",
        "    P_x0, P_x1, P_x0_grid, P_x1_grid, accuracy[0] = measurement_pure( train_QFM_x0, train_QFM_x1, test_QFM_x, test_lb, grid_QFM)\n",
        "\n",
        "    if plot: plot_clasification(grid_xy, test_arr, test_lb, P_x0_grid, P_x1_grid, accuracy[0], dataset, quantum_feature_map, 'pure')\n",
        "\n",
        "    # Generate density matrices outside 'measurement_mixed'\n",
        "    #mdensity_x0 = mixed_density(train_QFM_x0)\n",
        "    #mdensity_x1 = mixed_density(train_QFM_x1)\n",
        "\n",
        "    # Reduce the matrix dimension\n",
        "    #mdensity_x0 = reduce_matrix(mdensity_x0, threshold=0.01)\n",
        "    #mdensity_x1 = reduce_matrix(mdensity_x1, threshold=0.01)\n",
        "    ### The reduction is not useful here because it keeps the original matrix dimension\n",
        "\n",
        "    P_x0, P_x1, P_x0_grid, P_x1_grid, accuracy[1], mdensity_x0, mdensity_x1 = measurement_mixed( train_QFM_x0, train_QFM_x1, test_QFM_x, test_lb, grid_QFM)#, density_x0 = mdensity_x0, density_x1 = mdensity_x1)\n",
        "\n",
        "    if plot: plot_clasification(grid_xy, test_arr, test_lb, P_x0_grid, P_x1_grid, accuracy[1], dataset, quantum_feature_map, 'mixed')\n",
        "\n",
        "    ## Trace product\n",
        "    int_prod = np.abs(np.trace(np.matmul(mdensity_x0,mdensity_x1)))\n",
        "\n",
        "    # Cut the lowest eigenvectors\n",
        "    #mdensity_x0 = reduce_matrix(mdensity_x0, threshold=0.001)\n",
        "    #mdensity_x1 = reduce_matrix(mdensity_x1, threshold=0.001)\n",
        "\n",
        "    mdensity_x0 = mdensity_x0 / np.trace(mdensity_x0)\n",
        "    mdensity_x1 = mdensity_x1 / np.trace(mdensity_x1)\n",
        "\n",
        "    ## Fidelity\n",
        "    #fidelity_value = state_fidelity(mdensity_x0,mdensity_x1)\n",
        "\n",
        "    P_x0, P_x1, P_x0_grid, P_x1_grid, accuracy[2] = measurement_diagonal( train_QFM_x0, train_QFM_x1, test_QFM_x, test_lb, grid_QFM, density_x0 = mdensity_x0, density_x1 = mdensity_x1)\n",
        "\n",
        "    if plot: plot_clasification(grid_xy, test_arr, test_lb, P_x0_grid, P_x1_grid, accuracy[2], dataset, quantum_feature_map, 'classical')\n",
        "\n",
        "    return accuracy, int_prod, 0#fidelity_value\n",
        "\n",
        "#clasification_and_accuracies(coherent, num_points, N_qfm, param_qfm, N_grid, random_seed, generate_spirals, plot = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jj_q97QewH21"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "def global_minimum(data, sigma):\n",
        "    \"\"\"\n",
        "    Finds the global minimum after softening the data with a Gaussian filter.\n",
        "\n",
        "    Parameters:\n",
        "    - data (array-like): The input data.\n",
        "    - sigma (float): The standard deviation for Gaussian smoothing.\n",
        "\n",
        "    Returns:\n",
        "    - float: The global minimum of the smoothed data.\n",
        "    \"\"\"\n",
        "    smoothed_data = gaussian_filter(data, sigma=sigma)\n",
        "    return np.min(smoothed_data), np.argmin(smoothed_data)\n",
        "\n",
        "def global_maximum(data, sigma):\n",
        "    \"\"\"\n",
        "    Finds the global maximum after softening the data with a Gaussian filter.\n",
        "\n",
        "    Parameters:\n",
        "    - data (array-like): The input data.\n",
        "    - sigma (float): The standard deviation for Gaussian smoothing.\n",
        "\n",
        "    Returns:\n",
        "    - float: The global maximum of the smoothed data.\n",
        "    \"\"\"\n",
        "    smoothed_data = gaussian_filter(data, sigma=sigma)\n",
        "    return np.max(smoothed_data), np.argmax(smoothed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AXBow-IpfhRy"
      },
      "outputs": [],
      "source": [
        "def save_arrays_to_file(arrays, variable_names, filename):\n",
        "    \"\"\"\n",
        "    Saves a list of arrays into a dictionary and exports them to a .npz file.\n",
        "\n",
        "    Parameters:\n",
        "    - arrays (list of np.ndarray): The list of arrays to save.\n",
        "    - variable_names (list of str): The corresponding names for the arrays.\n",
        "    - filename (str): The file name to save the arrays.\n",
        "    \"\"\"\n",
        "    if len(arrays) != len(variable_names):\n",
        "        raise ValueError(\"Number of arrays and variable names must match.\")\n",
        "\n",
        "    array_dict = {name: array for name, array in zip(variable_names, arrays)}\n",
        "    np.savez(filename, **array_dict)\n",
        "    print(f\"Arrays saved to {filename}\")\n",
        "\n",
        "def load_arrays_from_file(filename):\n",
        "    \"\"\"\n",
        "    Loads arrays from a .npz file and returns a dictionary of them.\n",
        "\n",
        "    Parameters:\n",
        "    - filename (str): The file name to load the arrays from.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary where keys are variable names and values are arrays.\n",
        "    \"\"\"\n",
        "    loaded_data = np.load(filename)\n",
        "    array_dict = {key: loaded_data[key] for key in loaded_data.files}\n",
        "    print(f\"Arrays loaded from {filename}\")\n",
        "    return array_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uvUczDlyjaln"
      },
      "outputs": [],
      "source": [
        "from scipy.linalg import sqrtm\n",
        "\n",
        "def fidelity(p,q):\n",
        "    return np.trace(sqrtm(np.matmul(np.matmul(sqrtm(p),q),sqrtm(p))))**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "oZGDg7CRZZQi",
        "outputId": "5efbf621-58fe-4b38-c952-895bfaff61e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ndef fidelity_eigen(p,q, cutting_fraction = 0.01):\\n    eigenvalues_p, eigenvectors_p = np.linalg.eigh(p)\\n    eigenvalues_q, eigenvectors_q = np.linalg.eigh(q)\\n    # Sort eigenvalues and eigenvectors in descending order\\n    '''\\n    sorted_indices_p = np.argsort(eigenvalues_p)[::-1]\\n    sorted_indices_q = np.argsort(eigenvalues_q)[::-1]\\n    eigenvalues_p = eigenvalues_p[sorted_indices_p]\\n    eigenvalues_q = eigenvalues_q[sorted_indices_q]\\n    eigenvectors_p = eigenvectors_p[:, sorted_indices_p]\\n    eigenvectors_q = eigenvectors_q[:, sorted_indices_q]'''\\n\\n    eigenvalues_p = eigenvalues_p[::-1]\\n    eigenvalues_q = eigenvalues_q[::-1]\\n    eigenvectors_p = eigenvectors_p[:, ::-1]\\n    eigenvectors_q = eigenvectors_q[:, ::-1]\\n\\n    first_index_p = np.argmax(eigenvalues_p > eigenvalues_p[0]*cutting_fraction)\\n    first_index_q = np.argmax(eigenvalues_q > eigenvalues_q[0]*cutting_fraction)\\n\\n    # Keep just the larger eigenvalues and their eigenvectors\\n    eigenvalues_p = eigenvalues_p[0:first_index_p]\\n    eigenvectors_p = eigenvectors_p[:, 0:first_index_p]\\n    eigenvalues_q = eigenvalues_q[0:first_index_q]\\n    eigenvectors_q = eigenvectors_q[:, 0:first_index_q]\\n\\n    ### At this moment the programer notices that there are reasons why are optimized and predefined functions\\n\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "def fidelity_eigen(p,q, cutting_fraction = 0.01):\n",
        "    eigenvalues_p, eigenvectors_p = np.linalg.eigh(p)\n",
        "    eigenvalues_q, eigenvectors_q = np.linalg.eigh(q)\n",
        "    # Sort eigenvalues and eigenvectors in descending order\n",
        "    '''\n",
        "    sorted_indices_p = np.argsort(eigenvalues_p)[::-1]\n",
        "    sorted_indices_q = np.argsort(eigenvalues_q)[::-1]\n",
        "    eigenvalues_p = eigenvalues_p[sorted_indices_p]\n",
        "    eigenvalues_q = eigenvalues_q[sorted_indices_q]\n",
        "    eigenvectors_p = eigenvectors_p[:, sorted_indices_p]\n",
        "    eigenvectors_q = eigenvectors_q[:, sorted_indices_q]'''\n",
        "\n",
        "    eigenvalues_p = eigenvalues_p[::-1]\n",
        "    eigenvalues_q = eigenvalues_q[::-1]\n",
        "    eigenvectors_p = eigenvectors_p[:, ::-1]\n",
        "    eigenvectors_q = eigenvectors_q[:, ::-1]\n",
        "\n",
        "    first_index_p = np.argmax(eigenvalues_p > eigenvalues_p[0]*cutting_fraction)\n",
        "    first_index_q = np.argmax(eigenvalues_q > eigenvalues_q[0]*cutting_fraction)\n",
        "\n",
        "    # Keep just the larger eigenvalues and their eigenvectors\n",
        "    eigenvalues_p = eigenvalues_p[0:first_index_p]\n",
        "    eigenvectors_p = eigenvectors_p[:, 0:first_index_p]\n",
        "    eigenvalues_q = eigenvalues_q[0:first_index_q]\n",
        "    eigenvectors_q = eigenvectors_q[:, 0:first_index_q]\n",
        "\n",
        "    ### At this moment the programer notices that there are reasons why are optimized and predefined functions\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9ZxRz9SRIO_",
        "outputId": "ac28f39b-d9da-4f09-c0f2-a7ed02875fa0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 0, 1, 3])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.argsort([2,3,1,5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1BMNfuWRJqg"
      },
      "source": [
        "# Main for pure, mixed, diag and internal product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-aKtQSJdmsk",
        "outputId": "ffbb9f16-716b-4461-82cc-7f166c289349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For N = 10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For N = 15\n",
            "For N = 20\n",
            "For N = 25\n",
            "Execution time: 237.2606282234192 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "###################\n",
        "\n",
        "quantum_feature_map = coherent\n",
        "num_points = 100\n",
        "dataset_generator = generate_spirals\n",
        "N_grid = 1\n",
        "\n",
        "N_qfm_arr = np.arange(10, 30, 5, dtype='int')\n",
        "param_qfm_arr = np.linspace(1, 45, 10)\n",
        "random_max = 3\n",
        "\n",
        "acc_all = np.zeros((len(N_qfm_arr),len(param_qfm_arr),random_max,3))\n",
        "acc_mean = np.zeros((len(N_qfm_arr),len(param_qfm_arr),3))\n",
        "acc_std = np.zeros((len(N_qfm_arr),len(param_qfm_arr),3))\n",
        "\n",
        "internal_all = np.zeros((len(N_qfm_arr),len(param_qfm_arr),random_max))\n",
        "internal_mean = np.zeros((len(N_qfm_arr),len(param_qfm_arr)))\n",
        "internal_std = np.zeros((len(N_qfm_arr),len(param_qfm_arr)))\n",
        "\n",
        "fidelity_all = np.zeros((len(N_qfm_arr),len(param_qfm_arr),random_max))\n",
        "fidelity_mean = np.zeros((len(N_qfm_arr),len(param_qfm_arr)))\n",
        "fidelity_std = np.zeros((len(N_qfm_arr),len(param_qfm_arr)))\n",
        "\n",
        "# Reduce the eigenvectors amount\n",
        "for i, N_qfm in enumerate(N_qfm_arr):\n",
        "  print(f'For N = {N_qfm}')\n",
        "  for j, param_qfm in enumerate(param_qfm_arr):\n",
        "    #print(param_qfm)\n",
        "    for random_seed in range(random_max):\n",
        "        acc_all[i,j,random_seed], internal_all[i,j,random_seed], fidelity_all[i,j,random_seed] = clasification_and_accuracies(quantum_feature_map, num_points, N_qfm, param_qfm, N_grid, random_seed, dataset_generator)#, plot=True)\n",
        "        #print(acc_all[i,j,random_seed])\n",
        "\n",
        "\n",
        "acc_mean = np.mean(acc_all,axis=2)\n",
        "acc_std = np.std(acc_all, axis=2)\n",
        "internal_mean = np.mean(internal_all,axis=2)\n",
        "internal_std = np.std(internal_all, axis=2)\n",
        "fidelity_mean = np.mean(fidelity_all,axis=2)\n",
        "fidelity_std = np.std(fidelity_all, axis=2)\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For N = 60\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "###################\n",
        "\n",
        "N_qfm_arr2 =[60,70] #np.arange(60,71,10, dtype='int')\n",
        "\n",
        "acc_all2 = np.zeros((len(N_qfm_arr2),len(param_qfm_arr),random_max,3))\n",
        "acc_mean2 = np.zeros((len(N_qfm_arr2),len(param_qfm_arr),3))\n",
        "acc_std2 = np.zeros((len(N_qfm_arr2),len(param_qfm_arr),3))\n",
        "\n",
        "internal_all2 = np.zeros((len(N_qfm_arr2),len(param_qfm_arr),random_max))\n",
        "internal_mean2 = np.zeros((len(N_qfm_arr2),len(param_qfm_arr)))\n",
        "internal_std2 = np.zeros((len(N_qfm_arr2),len(param_qfm_arr)))\n",
        "\n",
        "fidelity_all2 = np.zeros((len(N_qfm_arr2),len(param_qfm_arr),random_max))\n",
        "fidelity_mean2 = np.zeros((len(N_qfm_arr2),len(param_qfm_arr)))\n",
        "fidelity_std2 = np.zeros((len(N_qfm_arr2),len(param_qfm_arr)))\n",
        "\n",
        "# Reduce the eigenvectors amount\n",
        "for i, N_qfm in enumerate(N_qfm_arr2):\n",
        "  print(f'For N = {N_qfm}')\n",
        "  for j, param_qfm in enumerate(param_qfm_arr):\n",
        "    #print(param_qfm)\n",
        "    for random_seed in range(random_max):\n",
        "        acc_all2[i,j,random_seed], internal_all2[i,j,random_seed], fidelity_all2[i,j,random_seed] = clasification_and_accuracies(quantum_feature_map, num_points, N_qfm, param_qfm, N_grid, random_seed, dataset_generator)#, plot=True)\n",
        "        #print(acc_all[i,j,random_seed])\n",
        "\n",
        "acc_mean2 = np.mean(acc_all2,axis=2)\n",
        "acc_std2 = np.std(acc_all2, axis=2)\n",
        "internal_mean2 = np.mean(internal_all2,axis=2)\n",
        "internal_std2 = np.std(internal_all2, axis=2)\n",
        "fidelity_mean2 = np.mean(fidelity_all2,axis=2)\n",
        "fidelity_std2 = np.std(fidelity_all2, axis=2)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc_all = np.concatenate((acc_all, acc_all2), axis=0)\n",
        "acc_mean = np.concatenate((acc_mean, acc_mean2), axis=0)\n",
        "acc_std = np.concatenate((acc_std, acc_std2), axis=0)\n",
        "\n",
        "internal_all = np.concatenate((internal_all, internal_all2), axis=0)\n",
        "internal_mean = np.concatenate((internal_mean, internal_mean2), axis=0)\n",
        "internal_std = np.concatenate((internal_std, internal_std2), axis=0)\n",
        "\n",
        "fidelity_all = np.concatenate((fidelity_all, fidelity_all2), axis=0)\n",
        "fidelity_mean = np.concatenate((fidelity_mean, fidelity_mean2), axis=0)\n",
        "fidelity_std = np.concatenate((fidelity_std, fidelity_std2), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTn35nknPkGu"
      },
      "source": [
        "I didn't find a way to optimize with reduction of the matrix\n",
        "\n",
        "N_qfm_arr = [32] #np.linspace(1,30,2)\n",
        "param_qfm_arr = np.linspace(1,120,5)\n",
        "random_max = 1\n",
        "\n",
        "With F, Execution time: 64.65034747123718 seconds\n",
        "\n",
        "Without, Execution time: 14.389471530914307 seconds\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHG4MVj4pSi0"
      },
      "outputs": [],
      "source": [
        "#param_qfm_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPa0-3nFKMpN",
        "outputId": "5fc8e06b-efc8-495c-b04c-05582dca0cd7"
      },
      "outputs": [],
      "source": [
        "### SAVING\n",
        "\n",
        "\n",
        "# Get the current time as a time struct\n",
        "current_time = time.localtime()\n",
        "\n",
        "# Extract individual components\n",
        "month = current_time.tm_mon  # Month (1-12)\n",
        "day = current_time.tm_mday   # Day of the month (1-31)\n",
        "hour = current_time.tm_hour  # Hour (0-23)\n",
        "minute = current_time.tm_min # Minute (0-59)\n",
        "\n",
        "\n",
        "arrays = [acc_mean, acc_std, internal_mean, internal_std, fidelity_mean, fidelity_std]\n",
        "variable_names = ['acc_mean', 'acc_std', 'internal_mean', 'internal_std', 'fidelity_mean', 'fidelity_std']\n",
        "\n",
        "qfm_name = (quantum_feature_map.__name__)[:3]\n",
        "dataset_name = (dataset_generator.__name__)[9:12]\n",
        "print(qfm_name)\n",
        "print(dataset_name)\n",
        "filename = qfm_name + '-' + dataset_name + f'-{day}-{month}-{hour}'\n",
        "filename = directory_arrays + filename\n",
        "\n",
        "save_arrays_to_file(arrays, variable_names, filename)\n",
        "#loaded_arrays = load_arrays_from_file(filename)\n",
        "#print(loaded_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4AGsz_evbC6G",
        "outputId": "0f1a14d3-a5c8-4885-d325-bcd9b96ab1d6"
      },
      "outputs": [],
      "source": [
        "# Plotting Accuracy vs Beta for a fixed N\n",
        "fixed_N_index = 0\n",
        "for fixed_N_index in range(len(N_qfm_arr)):\n",
        "  print(f'For N = {N_qfm_arr[fixed_N_index]}')\n",
        "  plt.figure(figsize=(10, 5))\n",
        "\n",
        "  # Plot accuracy for pure measurement\n",
        "  #plt.plot(param_qfm_arr, acc_mean[fixed_N_index, :, 0], label='Pure Measurement', color='b')\n",
        "  #plt.fill_between(param_qfm_arr, acc_mean[fixed_N_index, :, 0] - acc_std[fixed_N_index, :, 0],\n",
        "  #                acc_mean[fixed_N_index, :, 0] + acc_std[fixed_N_index, :, 0], color='b', alpha=0.2)\n",
        "  # Plot accuracy for mixed measurement\n",
        "  plt.plot(param_qfm_arr, acc_mean[fixed_N_index, :, 1], label='Mixed Measurement',color='r')\n",
        "  plt.fill_between(param_qfm_arr, acc_mean[fixed_N_index, :, 1] - acc_std[fixed_N_index, :, 1],\n",
        "                  acc_mean[fixed_N_index, :, 1] + acc_std[fixed_N_index, :, 1], color='r', alpha=0.2)\n",
        "  # Plot accuracy for diagonal of mixed measurement\n",
        "  #plt.plot(param_qfm_arr, acc_mean[fixed_N_index, :, 2], label='Clasical Measurement', color='g')\n",
        "  #plt.fill_between(param_qfm_arr, acc_mean[fixed_N_index, :, 2] - acc_std[fixed_N_index, :, 2],\n",
        "  #                acc_mean[fixed_N_index, :, 2] + acc_std[fixed_N_index, :, 2], color='g', alpha=0.2)\n",
        "  # Plot internal product average\n",
        "  plt.plot(param_qfm_arr, internal_mean[fixed_N_index, :], label='Internal Product', color='y')\n",
        "  plt.fill_between(param_qfm_arr, internal_mean[fixed_N_index, :] - internal_std[fixed_N_index, :],\n",
        "                  internal_mean[fixed_N_index, :] + internal_std[fixed_N_index, :], color='y', alpha=0.2)\n",
        "  # Plot fidelity average\n",
        "  #plt.plot(param_qfm_arr, fidelity_mean[fixed_N_index, :], label='Fidelity', color='m')\n",
        "  #plt.fill_between(param_qfm_arr, fidelity_mean[fixed_N_index, :] - fidelity_std[fixed_N_index, :],\n",
        "  #                fidelity_mean[fixed_N_index, :] + fidelity_std[fixed_N_index, :], color='m', alpha=0.2)\n",
        "\n",
        "  plt.title(f'Accuracy vs Beta for N = {N_qfm_arr[fixed_N_index]}')\n",
        "  plt.xlabel('Beta')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX0YqkYfjTfu"
      },
      "outputs": [],
      "source": [
        "#print(\"\\033[34m\" + str(acc_mean) + \"\\033[0m\")  # Blue for acc_mean\n",
        "#print(\"\\033[32m\" + str(acc_std) + \"\\033[0m\")  # Green for acc_std\n",
        "#print(\"\\033[33m\" + str(acc_all) + \"\\033[0m\")  # Yellow for acc_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzN0tdo_uCoP",
        "outputId": "2f7a22f0-336a-426b-ad68-0e295ab4d30c"
      },
      "outputs": [],
      "source": [
        "min_IP_all = np.min(internal_mean)\n",
        "index_min_IP_all = np.unravel_index(np.argmin(internal_mean), internal_mean.shape)\n",
        "print('Internal product minimum')\n",
        "print(N_qfm_arr[index_min_IP_all[0]])\n",
        "print(param_qfm_arr[index_min_IP_all[1]])\n",
        "print(min_IP_all)\n",
        "\n",
        "max_MIXED_all = np.max(acc_mean[:,:,1])\n",
        "index_max_MIXED_all = np.unravel_index(np.argmax(acc_mean[:,:,1]), acc_mean[:,:,1].shape)\n",
        "print('Mixed accuracy maximum')\n",
        "print(N_qfm_arr[index_max_MIXED_all[0]])\n",
        "print(param_qfm_arr[index_max_MIXED_all[1]])\n",
        "print(max_MIXED_all)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E57fV8ckwww7",
        "outputId": "c2572827-de27-40f1-bea9-e905a076dc93"
      },
      "outputs": [],
      "source": [
        "for fixed_N_index in range(len(N_qfm_arr)):\n",
        "  print(f'For N = {N_qfm_arr[fixed_N_index]}')\n",
        "  min_ip = global_minimum(internal_mean[fixed_N_index, :], np.mean(internal_std[fixed_N_index, :]))\n",
        "  min_fid = global_minimum(fidelity_mean[fixed_N_index, :], np.mean(fidelity_std[fixed_N_index, :]))\n",
        "  max_pure = global_maximum(acc_mean[fixed_N_index, :, 0], np.mean(acc_std[fixed_N_index, :, 0]))\n",
        "  max_mix = global_maximum(acc_mean[fixed_N_index, :, 1], np.mean(acc_std[fixed_N_index, :, 1]))\n",
        "  max_diag = global_maximum(acc_mean[fixed_N_index, :, 2], np.mean(acc_std[fixed_N_index, :, 2]))\n",
        "\n",
        "\n",
        "  print(f'Minimum internal mean reached at {param_qfm_arr[min_ip[1]]} with the value of {min_ip[0]}')\n",
        "  #print(f'Minimum fidelity mean reached at {param_qfm_arr[min_fid[1]]} with the value of {min_fid[0]}')\n",
        "\n",
        "  print(f'Maximum MIXED accuracy reached at {param_qfm_arr[max_mix[1]]} with the value of {max_mix[0]}')\n",
        "  #print(f'Maximum pure accuracy reached at {param_qfm_arr[max_pure[1]]} with the value of {max_pure[0]}')\n",
        "  #print(f'Maximum diagonal accuracy reached at {param_qfm_arr[max_diag[1]]} with the value of {max_diag[0]}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB81sehhJm8x"
      },
      "source": [
        "For Coherent, Spirals, dim = 32, numpoints=200, 7 random\n",
        "\n",
        "*   Minimum internal mean reached in 64.9625 with value 0.013364475339075274\n",
        "*   Minimum fidelity mean reached in 48.6 with value 0.09765225252448362\n",
        "*   Maximum MIXED accuracy reached in 44.1375 with value 0.9657142857142856\n",
        "*   Maximum pure accuracy reached in 66.45 with value 0.85\n",
        "*   Maximum diagonal accuracy reached in 41.1625 with value 0.9228571428571427\n",
        "\n",
        "For Coherent, Moons, ...\n",
        "\n",
        "*  Minimum internal mean reached at 47.112500000000004 with the value of 0.0008042185802515273\n",
        "*  Minimum fidelity mean reached at 47.112500000000004 with the value of 0.004002503688026683\n",
        "*  Maximum MIXED accuracy reached at 23.3125 with the value of 0.9942857142857143\n",
        "*  Maximum pure accuracy reached at 35.2125 with the value of 0.9942857142857143\n",
        "*  Maximum diagonal accuracy reached at 39.675000000000004 with the value of 0.9771428571428572\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJWlLYuv7KzD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH4JRLSMRg9u"
      },
      "source": [
        "## Smoothed plot, just for checking the smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0hZJLeg7LN6",
        "outputId": "4734f8a8-41ec-41b4-9899-1bcb6eabf26d"
      },
      "outputs": [],
      "source": [
        "# Plotting Accuracy vs Beta for a fixed N\n",
        "fixed_N_index = 0\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "sigma_pure  = np.mean(acc_std[fixed_N_index, :, 0])\n",
        "sigma_mixed = np.mean(acc_std[fixed_N_index, :, 1])\n",
        "sigma_diag  = np.mean(acc_std[fixed_N_index, :, 2])\n",
        "pure_smooth = gaussian_filter(acc_mean[fixed_N_index, :, 0], sigma=sigma_pure)\n",
        "mixed_smooth = gaussian_filter(acc_mean[fixed_N_index, :, 1], sigma=sigma_mixed)\n",
        "diag_smooth = gaussian_filter(acc_mean[fixed_N_index, :, 2], sigma=sigma_diag)\n",
        "\n",
        "sigma_internal = np.mean(internal_std[fixed_N_index, :])\n",
        "internal_smooth = gaussian_filter(internal_mean[fixed_N_index, :], sigma=sigma_internal)\n",
        "\n",
        "sigma_fidelity = np.mean(fidelity_std[fixed_N_index, :])\n",
        "fidelity_smooth = gaussian_filter(fidelity_mean[fixed_N_index, :], sigma=sigma_fidelity)\n",
        "\n",
        "# Plot accuracy for pure measurement\n",
        "plt.plot(param_qfm_arr, pure_smooth, label='Pure Measurement', color='b')\n",
        "plt.fill_between(param_qfm_arr, acc_mean[fixed_N_index, :, 0] - acc_std[fixed_N_index, :, 0], acc_mean[fixed_N_index, :, 0] + acc_std[fixed_N_index, :, 0], color='b', alpha=0.2)\n",
        "# Plot accuracy for mixed measurement\n",
        "plt.plot(param_qfm_arr, mixed_smooth, label='Mixed Measurement',color='r')\n",
        "plt.fill_between(param_qfm_arr, acc_mean[fixed_N_index, :, 1] - acc_std[fixed_N_index, :, 1], acc_mean[fixed_N_index, :, 1] + acc_std[fixed_N_index, :, 1], color='r', alpha=0.2)\n",
        "# Plot accuracy for diagonal of mixed measurement\n",
        "plt.plot(param_qfm_arr, diag_smooth, label='Clasical Measurement', color='g')\n",
        "plt.fill_between(param_qfm_arr, acc_mean[fixed_N_index, :, 2] - acc_std[fixed_N_index, :, 2], acc_mean[fixed_N_index, :, 2] + acc_std[fixed_N_index, :, 2], color='g', alpha=0.2)\n",
        "# Plot internal product average\n",
        "plt.plot(param_qfm_arr, internal_smooth, label='Internal Product', color='y')\n",
        "plt.fill_between(param_qfm_arr, internal_mean[fixed_N_index, :] - internal_std[fixed_N_index, :], internal_mean[fixed_N_index, :] + internal_std[fixed_N_index, :], color='y', alpha=0.2)\n",
        "# Plot fidelity average\n",
        "plt.plot(param_qfm_arr, fidelity_smooth, label='Fidelity', color='m')\n",
        "plt.fill_between(param_qfm_arr, fidelity_mean[fixed_N_index, :] - fidelity_std[fixed_N_index, :], fidelity_mean[fixed_N_index, :] + fidelity_std[fixed_N_index, :], color='m', alpha=0.2)\n",
        "\n",
        "\n",
        "plt.title(f'Smoothed Accuracy vs Beta for N = {N_qfm_arr[fixed_N_index]}')\n",
        "plt.xlabel('Beta')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHw_m-spMT66"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouOn52kQQWy2"
      },
      "source": [
        "# Trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-OwZ7UjPrBF",
        "outputId": "23a5b77f-7467-4db4-b823-9804b9793447"
      },
      "outputs": [],
      "source": [
        "'''''''''''''''\n",
        "### COHERENT\n",
        "\n",
        "num_points = 1000\n",
        "N_qfm = 30 #Dimensions of QFM\n",
        "param_qfm = 70 #Parameter\n",
        "N_grid = 50 #Number of points in grid per axis\n",
        "quantum_feature_map = coherent\n",
        "dataset = 'Spiral'\n",
        "random_max = 10\n",
        "\n",
        "acc_mean = np.zeros(3)\n",
        "acc_std = np.zeros(3)\n",
        "\n",
        "acc_all_seeds = np.zeros((random_max, 3))\n",
        "for random_seed in range(random_max):\n",
        "    accuracy = np.zeros(3) #The for pure and mixed and diagonal\n",
        "\n",
        "    train_arr, train_lb, test_arr, test_lb = generate_spirals(num_points, random_seed)\n",
        "\n",
        "    grid_QFM, grid_xy = make_grid(quantum_feature_map, N_qfm, param_qfm, N_grid)\n",
        "\n",
        "    train_QFM_x0, train_QFM_x1, test_QFM_x = make_QFM(quantum_feature_map, N_qfm, param_qfm, train_arr, train_lb, test_arr)\n",
        "\n",
        "    P_x0, P_x1, P_x0_grid, P_x1_grid, accuracy[0] = measurement_pure( train_QFM_x0, train_QFM_x1, test_QFM_x, test_lb, grid_QFM)\n",
        "\n",
        "    plot_clasification(grid_xy, test_arr, test_lb, P_x0_grid, P_x1_grid, accuracy[0], dataset, quantum_feature_map, 'pure')\n",
        "\n",
        "    P_x0, P_x1, P_x0_grid, P_x1_grid, accuracy[1], mdensity_x0, mdensity_x1 = measurement_mixed( train_QFM_x0, train_QFM_x1, test_QFM_x, test_lb, grid_QFM)\n",
        "\n",
        "    plot_clasification(grid_xy, test_arr, test_lb, P_x0_grid, P_x1_grid, accuracy[1], dataset, quantum_feature_map, 'mixed')\n",
        "\n",
        "    P_x0, P_x1, P_x0_grid, P_x1_grid, accuracy[2] = measurement_diagonal( train_QFM_x0, train_QFM_x1, test_QFM_x, test_lb, grid_QFM, density_x0 = mdensity_x0, density_x1 = mdensity_x1)\n",
        "\n",
        "    plot_clasification(grid_xy, test_arr, test_lb, P_x0_grid, P_x1_grid, accuracy[2], dataset, quantum_feature_map, 'classical')\n",
        "\n",
        "    acc_all_seeds[random_seed] = accuracy\n",
        "\n",
        "\n",
        "acc_mean = np.mean(acc_all_seeds, axis=0)\n",
        "acc_std = np.std(acc_all_seeds, axis=0)\n",
        "print(acc_mean)\n",
        "print(acc_std)\n",
        "\n",
        "'''''''''''''''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PH4JRLSMRg9u",
        "ouOn52kQQWy2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
